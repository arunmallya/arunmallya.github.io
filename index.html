
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
  <head>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
      /* Layout and HTML pieces the work of Jon Barron http://www.cs.berkeley.edu/~barron/ */
      a {
      color: #1772d1;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09227;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
      }
      tr {
        padding: 20px;
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700;
      }
      #teaser-td {
      text-align: center;
      margin: auto;
      display: block;
      }
      #teaser {
      width: 200px;
      border-style: none;
      margin-left: auto;
      margin-right: auto;
      }
      hr {
      border: 1px solid black;
      }
    </style>
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <title>Arun Mallya</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-34477541-5', 'auto');
      ga('send', 'pageview');
    </script>

  </head>

  <body>
    <table width="900" border="0" align="center" cellpadding="20">
      <tr>
	      <td>

          <table id="intro" width="100%" align="center" border="0" cellpadding="10">
            <tr>
              <td width="60%" valign="middle">
		            <p align="center"><font size="6">Arun Mallya</font></p>
		            <p align="justify">
                  I am a Senior Research Scientist at Nvidia Research.</br>
                  I graduated with a PhD from the
                  <a target="_blank" href="http://vision.cs.uiuc.edu/"> University of Illinois at Urbana-Champaign</a>,
		  where I explored computer vision under the guidance of Prof. <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a>.
                  <br>
                  I previously completed my Master's in CS at UIUC, and my Bachelor's in CSE at
                  <a target="_blank" href="http://www.iitkgp.ac.in/">IIT KGP</a>.<br><br>
                  My research focus is on doing more with neural networks.
		            </p>
		            <p align=center>
		              <a target="_blank" href="mailto:amallya-AT-nvidia.com">email</a> /
                  <a target="_blank" href="https://github.com/arunmallya/">Github</a> /
                  <a target="_blank" href="https://www.linkedin.com/pub/arun-mallya/50/5a/64">LinkedIn</a> /
                  <a target="_blank" href="https://scholar.google.com/citations?user=9OZvCVMAAAAJ&hl=en">Scholar</a> /
                  <a href="http://arunmallya.com">webpage</a>
		            </p>
              </td>
              <td width="17%">
                <br><br>
  		          <img loading="lazy" width="100%" src="images/arun_mallya.png" alt="A M">
	           </td>
            </tr>
          </table>

          <table id="heading" width="120%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <font size="5">Research</font>
              </td>
            </tr>
          </table>

      	  <table id="workworkwork" width="100%" align="center" cellpadding="20" style="background-color:#6AFF1C4D;">
            <tr>
                <td colspan="2" style="padding-bottom:0;">
                  <font size="3"><b>Generative Networks</b></font><hr>
                </td>
            </tr>

            <tr id="gancraft">
                <td width="25%" valign="top">
                  <img loading="lazy" id="teaser" src="teasers/gancraft.gif">
                </td>
                <td width="75%" valign="center">
                  <p>
                        <b>GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds (<span style="color:red">oral</span>)</b><br>
                        <a target="_blank" href="http://www.cs.cornell.edu/~zekun/">Zekun Hao</a>,
                        <strong>Arun Mallya</strong>,
                        <a target="_blank" href="https://blogs.cornell.edu/techfaculty/serge-belongie/">Serge Belongie</a>,
                        <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a><br>
                        <i>International Conference on Computer Vision</i> (ICCV), 2021 <br>
                        <a target="_blank" href="https://arxiv.org/abs/2104.07659">[arxiv preprint]</a>
                        <a target="_blank" href="https://nvlabs.github.io/GANcraft/">[project webpage and code]</a>
                  </p>
                </td>
            </tr>

            <tr id="face_vid2vid">
                <td width="25%" valign="top">
                  <img loading="lazy" id="teaser" src="teasers/face-vid2vid.gif">
                </td>
                <td width="75%" valign="center">
                  <p>
                        <b>One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing (<span style="color:red">oral</span>)</b><br>
                        <a target="_blank" href="https://tcwang0509.github.io/">Ting-Chun Wang</a>,
                        <strong>Arun Mallya</strong>,
                        <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a><br>
                        <i>Computer Vision and Pattern Recognition</i> (CVPR), 2021 <br>
                        <a target="_blank" href="https://arxiv.org/abs/2011.15126">[arxiv preprint]</a>
                        <a target="_blank" href="https://nvlabs.github.io/face-vid2vid/">[project webpage and code]</a>
                  </p>
                </td>
            </tr>

            <tr id="survey_2020">
                <td width="25%" valign="top">
                  <img loading="lazy" id="teaser" src="teasers/survey_2020.png">
                </td>
                <td width="75%" valign="center">
                  <p>
                        <b>Generative Adversarial Networks for Image and Video Synthesis:<br> Algorithms and Applications</b><br>
                        <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu*</a>,
                        <a target="_blank" href="http://www.cs.cornell.edu/~xhuang/">Xun Huang*</a>,
                        <a target="_blank" href="https://jiahuiyu.com/">Jiahui Yu*</a>,
                        <a target="_blank" href="https://tcwang0509.github.io/">Ting-Chun Wang*</a>,
                        <strong>Arun Mallya*</strong><br>
                        <i>Proceedings of the IEEE</i>, 2021 <br>
                        <a target="_blank" href="http://arxiv.org/abs/2008.02793">[arxiv preprint]</a>
                  </p>
                </td>
            </tr>

            <tr id="wc-vid2vid_eccv2020">
                <td width="25%" valign="top">
                  <img loading="lazy" id="teaser" src="teasers/wc-vid2vid.gif">
                </td>
                <td width="75%" valign="center">
                  <p>
                        <b>World-Consistent Video-to-Video Synthesis</b><br>
                        <strong>Arun Mallya*</strong>,
                        <a target="_blank" href="https://tcwang0509.github.io/">Ting-Chun Wang*</a>,
                        <a target="_blank" href="https://karansapra.github.io/">Karan Sapra</a>,
                        <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a><br>
                        <i>European Conference on Computer Vision</i> (ECCV), 2020 <br>
                        <a target="_blank" href="https://arxiv.org/abs/2007.08509">[arxiv preprint]</a>
                        <a target="_blank" href="https://nvlabs.github.io/wc-vid2vid/">[project webpage and code]</a>
                  </p>
                </td>
            </tr>

            <tr id="funit_iccv2019">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/funit-short.gif">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Few-Shot Unsupervised Image-to-Image Translation</b><br>
                  <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a>,
                  <a target="_blank" href="http://www.cs.cornell.edu/~xhuang/">Xun Huang</a>,
                  <strong>Arun Mallya</strong>,
                  <a target="_blank" href="https://research.nvidia.com/person/tero-karras">Tero Karras</a>,
                  <a target="_blank" href="https://users.aalto.fi/~ailat1/">Timo Aila</a>,
                  <a target="_blank" href="https://users.aalto.fi/~lehtinj7/">Jaakko Lehtinen</a>,
                  <a target="_blank" href="http://jankautz.com/">Jan Kautz</a><br>
                  <i>International Conference on Computer Vision</i> (ICCV), 2019 <br>
                  <a target="_blank" href="https://arxiv.org/abs/1905.01723">[arxiv preprint]</a>
                  <a target="_blank" href="https://nvlabs.github.io/`/">[project webpage and code]</a>
                </p>
              </td>
            </tr>

          </table>
          <table id="workworkwork" width="100%" align="center" cellpadding="20" style="background-color:#76E4E84D;">
            <tr>
                <td colspan="2" style="padding-bottom:0;">
                  <font size="3"><b>Interesting properties of Neural Networks, Efficient and Multi-Task Networks</b></font><hr>
                </td>
            </tr>

            <tr id="gradinversion">
                <td width="25%" valign="top">
                  <img loading="lazy" id="teaser" src="teasers/gradinversion.jpg">
                </td>
                <td width="75%" valign="center">
                  <p>
                      <b>See through Gradients: Image Batch Recovery via GradInversion</b><br>
                      Hongxu Yin,
                      <strong>Arun Mallya</strong>,
                      <a target="_blank" href="http://latentspace.cc/arash_vahdat/">Arash Vahdat</a>,
                      Jose Alvarez,
                      <a target="_blank" href="https://research.nvidia.com/person/pavlo-molchanov">Pavlo Molchanov</a>,
                      <a target="_blank" href="http://jankautz.com/">Jan Kautz</a><br>
                      <i>Computer Vision and Pattern Recognition</i> (CVPR), 2021 <br>
                      <a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.pdf">[paper]</a>
                  </p>
                </td>
            </tr>

            <tr id="dream">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/dream.jpg">
              </td>
              <td width="75%" valign="center">
                <p>
                    <b>Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion (<span style="color:red">oral</span>)</b><br>
                    Hongxu Yin,
                    <a target="_blank" href="https://research.nvidia.com/person/pavlo-molchanov">Pavlo Molchanov</a>,
                    Zhizhong Li,
                    Jose Alvarez,
                    <strong>Arun Mallya</strong>,
                    Derek Hoiem,
                    Niraj Jha,
                    <a target="_blank" href="http://jankautz.com/">Jan Kautz</a><br>
                    <i>Computer Vision and Pattern Recognition</i> (CVPR), 2020 <br>
                            <a target="_blank" href="https://arxiv.org/abs/1912.08795">[arxiv preprint]</a>
                    <a target="_blank" href="https://github.com/NVlabs/DeepInversion">[code]</a>
                </p>
              </td>
            </tr>

            <tr id="unas">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/unas.png">
              </td>
              <td width="75%" valign="center">
                <p>
                    <b>UNAS: Differentiable Architecture Search Meets Reinforcement Learning (<span style="color:red">oral</span>)</b><br>
                    <a target="_blank" href="http://latentspace.cc/arash_vahdat/">Arash Vahdat</a>,
                    <strong>Arun Mallya</strong>,
                    <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a>,
                    <a target="_blank" href="http://jankautz.com/">Jan Kautz</a><br>
                    <i>Computer Vision and Pattern Recognition</i> (CVPR), 2020 <br>
                    <a target="_blank" href="https://arxiv.org/abs/1912.07651">[arxiv preprint]</a>
                </p>
              </td>
            </tr>

            <tr id="pruning_cvpr2019">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/pruning_cvpr2019.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Importance Estimation for Neural Network Pruning </b><br>
                  <a target="_blank" href="https://research.nvidia.com/person/pavlo-molchanov">Pavlo Molchanov</a>,
                  <strong>Arun Mallya</strong>,
                  <a target="_blank" href="https://research.nvidia.com/person/stephen-tyree">Stephen Tyree</a>,
                  <a target="_blank" href="https://research.nvidia.com/person/iuri-frosio">Iuri Frosio</a>,
                  <a target="_blank" href="http://jankautz.com/">Jan Kautz</a><br>
                  <i>Computer Vision and Pattern Recognition</i> (CVPR), 2019 <br>
                  <a target="_blank" href="https://arxiv.org/abs/1906.10771">[arxiv preprint]</a>
                  <a target="_blank" href="https://github.com/NVlabs/Taylor_pruning">[code]</a>
                </p>
              </td>
            </tr>

            <tr id="piggyback">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/piggyback.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Piggyback: Adding Multiple Tasks to a Single, Fixed Network by Learning to Mask</b><br>
                  <strong>Arun Mallya</strong>, Dillon Davis, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
                  <i>European Conference on Computer Vision</i> (ECCV), 2018 <br>
                  <a target="_blank" href="https://arxiv.org/abs/1801.06519">[arxiv preprint]</a>
		              <a target="_blank" href="https://github.com/arunmallya/piggyback18">[code]</a>
                </p>
              </td>
            </tr>

            <tr id="packnet">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/packnet.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</b><br>
                  <strong>Arun Mallya</strong>, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
			            <i>Computer Vision and Pattern Recognition</i> (CVPR), 2018 <br>
                  <a target="_blank" href="https://arxiv.org/abs/1711.05769">[arxiv preprint]</a>
		              <a target="_blank" href="https://github.com/arunmallya/packnet">[code]</a>
                </p>
              </td>
            </tr>

          </table>
          <table id="workworkwork" width="100%" align="center" cellpadding="20" style="background-color:#AD8FFF4D;">
            <tr>
                <td colspan="2" style="padding-bottom:0;">
                  <font size="3"><b>Vision and Language</b></font><hr>
                </td>
            </tr>

            <tr id="imsitu">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/imsitu.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Recurrent Models for Situation Recognition</b><br>
                  <strong>Arun Mallya</strong>, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
		              <i>International Conference on Computer Vision</i> (ICCV), 2017 <br>
                  <a target="_blank" href="https://arxiv.org/abs/1703.06233">[arxiv preprint]</a>
                  <a target="_blank" href="files/ICCV17_poster.pdf">[poster]</a>
                </p>
              </td>
            </tr>

            <tr id="grounding+vrd">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/grounding.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Phrase Localization and Visual Relationship Detection with Comprehensive Linguistic Cues</b><br>
                  Bryan A. Plummer, <strong>Arun Mallya</strong>, Christopher M. Cervantes, <a target="_blank" href="http://juliahmr.cs.illinois.edu/"> Julia Hockenmaier</a>, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
		              <i>International Conference on Computer Vision</i> (ICCV), 2017 <br>
                  <a target="_blank" href="https://arxiv.org/abs/1611.06641">[arxiv preprint]</a>
                </p>
              </td>
            </tr>

            <!-- <tr id="simple-vqa">
              <td id="teaser-td" width="25%" valign="top">
                <img loading="lazy" id="teaser" src="http://torch.ch/static/torch-logo.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  A torch implementation of the MLP VQA system, along with data from <br>
                  <b><a target="_blank" href="https://arxiv.org/abs/1606.08390">Revisiting Visual Question Answering Baselines</a></b>, ECCV'16,
                  can be found <a target="_blank" href="https://github.com/arunmallya/simple-vqa">here</a>.
                </p>
              </td>
            </tr> -->

            <tr id="eccv16-action">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/action_net.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Learning Models for Actions and Person-Object Interactions with Transfer to Question Answering</b><br>
                  <strong>Arun Mallya</strong>, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
                  <i>European Conference on Computer Vision</i> (ECCV), 2016 <br>
                  <a target="_blank" href="https://arxiv.org/abs/1604.04808">[arxiv preprint]</a>
                  <a target="_blank" href="https://uofi.box.com/s/yflrqbser1r5m3iez1satkprawmsouag">[caffemodels]</a>
                </p>
              </td>
            </tr>

            <tr id="bmvc16-vqa">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/bmvc_big.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Solving Visual Madlibs with Multiple Cues</b><br>
                  <a target="_blank" href="http://www.tatianatommasi.com/">Tatiana Tommasi</a>, <strong>Arun Mallya</strong>, Bryan Plummer, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a>, <a target="_blank" href="http://acberg.com/">Alex Berg</a>, <a target="_blank" href="http://tamaraberg.com/">Tamara Berg</a><br>
                  <i>British Machine Vision Conference</i> (BMVC), 2016 <br>
                  <a target="_blank" href="https://arxiv.org/abs/1608.03410">[arxiv preprint]</a> <br>
                  <i>International Journal of Computer Vision</i> (IJCV), 2016, submitted <br>
                  <a target="_blank" href="https://arxiv.org/abs/1611.00393">[arxiv preprint]</a> <br>
                  <p style="padding-top:0; margin-top:0; margin-bottom:0;"><b>Trained models:</b> <a target="_blank" href="https://uofi.box.com/s/yflrqbser1r5m3iez1satkprawmsouag">[caffemodels]</a></p>
                  <ol style="padding-top:0; margin-top:5; margin-bottom:0;">
                    <li> The Fusion model from the ECCV'16 paper above, trained on the HICO action dataset to predict 600
                      <a target="_blank" href="https://uofi.app.box.com/s/yflrqbser1r5m3iez1satkprawmsouag/file/107841785960">human-object interactions</a>.
                    <li> The Fusion model from the ECCV'16 paper above, trained on the MPII action dataset to predict 393 human actions.
                    <li> A VGG-16 model to predict 302
                      <a target="_blank" href="https://uofi.app.box.com/s/yflrqbser1r5m3iez1satkprawmsouag/file/99192676451">person attributes</a>
                      selected from the <a target="_blank" href="http://bplumme2.web.engr.illinois.edu/Flickr30kEntities/">Flickr30k Entities</a> dataset.
                  </ol>

                </p>
              </td>
            </tr>

          </table>
          <table id="workworkwork" width="100%" align="center" cellpadding="20" style="background-color:#E876784D;">
            <tr>
                <td colspan="2" style="padding-bottom:0;">
                  <font size="3"><b>Structured Prediction</b></font><hr>
                </td>
            </tr>

            <tr id="iccv15-indoor" onmouseout="defocus_stop()" onmouseover="defocus_start()" >
              <td width="25%">
                <div id='room' class='hidden' ><a href="teasers/room-2.png"><img loading="lazy" src="teasers/room-1.png"></a></div>
                <div id='edge' ><a href="teasers/room-1.png"><img loading="lazy" src="teasers/room-2.png"></a></div>
                <script type="text/javascript">
                  function defocus_start() {
                    document.getElementById('edge').style.display='inline';
                    document.getElementById('room').style.display='none';
                  }
                  function defocus_stop() {
                    document.getElementById('edge').style.display='none';
                    document.getElementById('room').style.display='inline';
                  }
                  defocus_stop()
                </script>
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Learning Informative Edge Maps for Indoor Scene Layout Prediction</b><br>
                  <strong>Arun Mallya</strong>, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
                  <i>International Conference on Computer Vision</i> (ICCV), 2015 <br>
                  <a target="_blank" href="http://slazebni.cs.illinois.edu/publications/iccv15_informative.pdf">[pdf]</a>
                  <a target="_blank" href="http://vision.cs.illinois.edu/downloads/indoor_scene_ICCV15/hedau+.tar.gz">[hedau+ dataset]</a>
                  <a target="_blank" href="http://vision.cs.illinois.edu/downloads/indoor_scene_ICCV15/hedau+_data.tar.gz">[hedau+ processed data]</a>
                </br>
                  <a target="_blank" href="http://vision.cs.illinois.edu/downloads/indoor_scene_ICCV15/hedau+_lmdb.tar">[hedau+ LMDBs (14GB)]</a>
                  <a target="_blank" href="http://vision.cs.illinois.edu/downloads/indoor_scene_ICCV15/caffe.tar.gz">[trained model + demo]</a>
                </p>
              </td>
            </tr>

      	    <tr id="bmvc15-birds">
      	      <td width="25%" valign="center">
      		      <img loading="lazy" id="teaser" src="teasers/bird.png">
      	      </td>
      	      <td width="75%" valign="center">
      		      <p>
                  <b>Part Localization using Multi-Proposal Consensus for Fine-Grained Categorization</b><br>
                  <a target="_blank" href="http://web.engr.illinois.edu/~kjshih2/index.html">Kevin J. Shih</a>, <strong>Arun Mallya</strong>, <a target="_blank" href="http://www.saurabhsingh.info/">Saurabh Singh</a>, <a target="_blank" href="http://dhoiem.cs.illinois.edu/">Derek Hoiem</a><br>
                  <i>British Machine Vision Conference</i> (BMVC), 2015 <br>
                  <a target="_blank" href="http://arxiv.org/abs/1507.06332">[arxiv preprint]</a>
                  <a target="_blank" href="files/BMVC_15_Poster.pdf">[poster]</a>
                  <a target="_blank" href="http://vision.cs.illinois.edu/keypoint_consensus/">[webpage]</a>
      		      </p>
      	      </td>
      	    </tr>

            <tr id="wacv-ped">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/ped.png">
              </td>
              <td width="75%" valign="center">
                <p>
                  <b>Unsupervised Deep Network Pretraining via Human Design</b><br>
                  <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a>, <strong>Arun Mallya</strong>, <a target="_blank" href="http://www.merl.com/people/oncel">Oncel C. Tuzel</a>, Xi Chen<br>
                  <i>Winter Conference on Applications of Computer Vision</i> (WACV), 2016 <br>
                  Work performed as a summer intern at <a target="_blank" href="http://www.merl.com/">MERL Cambridge</a> <br>
                  <a target="_blank" href="http://arxiv.org/abs/1502.05689">[arxiv preprint]</a>
                </p>
              </td>
            </tr>

          </table>

<!--      <hr>
          <table id="other_stuff" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <font size="5">Workshop Submissions</font></br>
              </td>
            </tr>
            <tr>
              <td width="100%" valign="top">
                <ol>
                  <li>
                    <a target="_blank" href="http://arunmallya.github.io/files/SUNw2017_motivations.pdf">High-level Cues for Predicting Motivations</a>
                    (<a target="_blank" href="http://arunmallya.github.io/files/SUNw2017_motivations_poster.pdf">poster</a>)
                    (<a target="_blank" href="http://arunmallya.github.io/files/SUNw2017_motivations_ppt.pptx">slides</a>)<br>
                    <strong>Arun Mallya</strong>, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
                    <i>Scene Understanding Workshop</i>, CVPR 2017 <br>
                  </li>
                  <br>
                  <li>
                    <a target="_blank" href="http://arunmallya.github.io/files/LVw2017_vrd.pdf">Visual Relationship Detection with Multiple Cues
                    (<a target="_blank" href="http://arunmallya.github.io/files/LVw2017_vrd_poster.pdf">poster</a>)<br>
                    <strong>Arun Mallya</strong>, Bryan A. Plummer, <a target="_blank" href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
                    <i>Language and Vision Workshop</i>, CVPR 2017 <br>
                  </li>
                </ol>
              </td>
            </tr>
          </table>
-->

          <hr>
          <table id="other_stuff" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <font size="5">Tutorials</font></br>
              </td>
            </tr>
            <tr>
              <td width="100%" valign="top">
                <ol>
                  <li> <a target="_blank" href="https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/">Accelerating Computer Vision with Mixed Precision, ECCV 2020</a> </li>
		  <li> <a target="_blank" href="https://nvlabs.github.io/iccv2019-mixed-precision-tutorial/">Accelerating Computer Vision with Mixed Precision, ICCV 2019</a> </li>
                </ol>
              </td>
            </tr>
          </table>

          <hr>
          <table id="other_stuff" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <font size="5">Writeups/Notes</font></br>
                Hosted on <a target="_blank" href="https://github.com/arunmallya/arunmallya.github.io/tree/master/writeups">github</a>. Edit requests/additions/corrections are welcome.
              </td>
            </tr>
            <tr>
              <td width="100%" valign="top">
                <ol>
                  <li> <a target="_blank" href="http://arunmallya.github.io/writeups/nn/backprop.html">A Backpropagation Refresher</a> </li>
                  <li> <a target="_blank" href="http://arunmallya.github.io/writeups/nn/lstm/index.html#/">An Illustrated Explanation of the LSTM Forward-Backward Pass</a> </li>
                  <li> <a target="_blank" href="http://slazebni.cs.illinois.edu/spring17/lec02_rnn.pdf">Introduction to RNNs</a> </li>
                  <li> <a target="_blank" href="http://slazebni.cs.illinois.edu/spring17/lec03_rnn.pdf">Introduction to RNNs - II</a> </li>
                  <li> <a target="_blank" href="https://gist.github.com/arunmallya/0e340cbc79c4f9545f97bf10d040cb65">Jupyter notebook to find Receptive Field Size and Effective Stride (supports dilated convs)</a> </li>
                  <li> <a target="_blank" href="http://jsfiddle.net/yces4vn9/43/">Visualization of neuron connections and receptive field of a CNN (including dilation)!</a> </li>
                </ol>
              </td>
            </tr>
          </table>

          <table id="thanks" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  <a href="http://www.cs.berkeley.edu/~barron/">(imitation is the sincerest form of flattery)</a>
                  </font>
                </p>
              </td>
            </tr>
          </table>

        </td>
      </tr>
    </table>
  </body>
</html>
