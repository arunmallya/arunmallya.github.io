<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

<head>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        /* Layout and HTML pieces the work of Jon Barron http://www.cs.berkeley.edu/~barron/ */
        a {
            color: #1772d1;
            text-decoration: none;
        }

        a:focus,
        a:hover {
            color: #f09227;
            text-decoration: none;
        }

        body,
        td,
        th {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px
        }

        tr {
            padding: 20px;
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
            font-weight: 700;
        }

        #teaser-td {
            text-align: center;
            margin: auto;
            display: block;
        }

        #teaser {
            width: 200px;
            border-style: none;
            margin-left: auto;
            margin-right: auto;
        }

        hr {
            border: 1px solid black;
        }
    </style>
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
        type='text/css'>
    <title>Arun Mallya</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">

    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-34477541-5', 'auto');
        ga('send', 'pageview');
    </script>

</head>

<body>
    <table width="900" border="0" align="center" cellpadding="20">
        <tr>
            <td>

                <table id="intro" width="100%" align="center" border="0" cellpadding="10">
                    <tr>
                        <td width="60%" valign="middle">
                            <p align="center">
                                <font size="6">Arun Mallya</font>
                            </p>
                            <p align="justify">
                                I am a Senior Research Scientist at Nvidia Research in the 
                                <a target="_blank" href="https://research.nvidia.com/labs/dir/">Deep Imagination Research (DIR)</a> group.</br>
                                I graduated with a PhD from the
                                <a target="_blank" href="http://vision.cs.uiuc.edu/"> University of Illinois at
                                    Urbana-Champaign</a>,
                                where I explored computer vision under the guidance of Prof. <a target="_blank"
                                    href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a>.
                                <br>
                                I previously completed my Master's in CS at UIUC, and my Bachelor's in CSE at
                                <a target="_blank" href="http://www.iitkgp.ac.in/">IIT KGP</a>.<br><br>
                                My research focus is on doing more with neural networks.
                            </p>
                            <p align=center>
                                <a target="_blank" href="mailto:amallya-AT-nvidia.com">email</a> /
                                <a target="_blank" href="https://github.com/arunmallya/">Github</a> /
                                <a target="_blank" href="https://www.linkedin.com/in/arun-m-06405a50">LinkedIn</a> /
                                <a target="_blank"
                                    href="https://scholar.google.com/citations?user=9OZvCVMAAAAJ&hl=en">Scholar</a> /
                                <a href="http://arunmallya.com">webpage</a>
                            </p>
                        </td>
                        <td width="17%">
                            <br><br>
                            <img loading="lazy" width="100%" src="images/arun_mallya.png" alt="A M">
                        </td>
                    </tr>
                </table>

                <table id="workworkwork" width="100%" align="center" cellpadding="20"
                    style="background-color:#6AFF1C4D;">
                    <tr>
                        <td colspan="2" style="padding-bottom:0;">
                            <font size="3"><b>Selected Research</b></font>
                            <hr>
                        </td>
                    </tr>

                    <tr id="spacex">
                        <td width="25%" valign="center">
                            <img loading="lazy" id="teaser" src="teasers/spacex.gif">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>SPACE: Speech-driven Portrait Animation with Controllable Expression</b><br>
                                <a target="_blank"
                                    href="https://research.nvidia.com/person/siddharth-gururani">Siddharth Gururani</a>,
                                <strong>Arun Mallya</strong>,
                                <a target="_blank" href="https://tcwang0509.github.io/">Ting-Chun Wang</a>,
                                <a target="_blank" href="https://rafaelvalle.github.io/">Rafael Valle</a>,
                                <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a><br>
                                <i>International Conference on Computer Vision</i> (ICCV), 2023 <br>
                                <a target="_blank" href="https://arxiv.org/abs/2211.09809">[arxiv preprint]</a>
                                <a target="_blank" href="https://research.nvidia.com/labs/dir/space/">[project webpage]</a>
                            </p>
                        </td>
                    </tr>

                    <tr id="imwa">
                        <td width="25%" valign="center">
                            <img loading="lazy" id="teaser" src="teasers/imwa.gif">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>Implicit Warping for Animation with Image Sets</b><br>
                                <strong>Arun Mallya</strong>,
                                <a target="_blank" href="https://tcwang0509.github.io/">Ting-Chun Wang</a>,
                                <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a><br>
                                <i>Neural Information Processing Systems</i> (NeurIPS), 2022 <br>
                                <a target="_blank" href="https://arxiv.org/abs/2210.01794">[arxiv preprint]</a>
                                <a target="_blank" href="https://research.nvidia.com/labs/dir/implicit_warping/">[project
                                    webpage]</a>
                            </p>
                        </td>
                    </tr>



                    <tr id="face_vid2vid">
                        <td width="25%" valign="center">
                            <img loading="lazy" id="teaser" src="teasers/face-vid2vid.gif">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing (<span
                                        style="color:red">oral</span>)</b><br>
                                <a target="_blank" href="https://tcwang0509.github.io/">Ting-Chun Wang</a>,
                                <strong>Arun Mallya</strong>,
                                <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a><br>
                                <i>Computer Vision and Pattern Recognition</i> (CVPR), 2021 <br>
                                <a target="_blank" href="https://arxiv.org/abs/2011.15126">[arxiv preprint]</a>
                                <a target="_blank" href="https://nvlabs.github.io/face-vid2vid/">[project webpage]</a>
                            </p>
                        </td>
                    </tr>

                    <tr id="loe">
                        <td width="25%" valign="top">
                            <img loading="lazy" id="teaser" src="teasers/LoE.svg">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>Implicit Neural Representations with Levels-of-Experts</b><br>
                                <a target="_blank" href="http://www.cs.cornell.edu/~zekun/">Zekun Hao</a>,
                                <strong>Arun Mallya</strong>,
                                <a target="_blank" href="https://blogs.cornell.edu/techfaculty/serge-belongie/">Serge
                                    Belongie</a>,
                                <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a><br>
                                <i>Neural Information Processing Systems</i> (NeurIPS), 2022 <br>
                                <a target="_blank" href="https://openreview.net/pdf?id=St5q10aqLTO">[paper]</a>
                            </p>
                        </td>
                    </tr>

                    <tr id="gancraft">
                        <td width="25%" valign="top">
                            <img loading="lazy" id="teaser" src="teasers/gancraft.gif">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds (<span
                                        style="color:red">oral</span>)</b><br>
                                <a target="_blank" href="http://www.cs.cornell.edu/~zekun/">Zekun Hao</a>,
                                <strong>Arun Mallya</strong>,
                                <a target="_blank" href="https://blogs.cornell.edu/techfaculty/serge-belongie/">Serge
                                    Belongie</a>,
                                <a target="_blank" href="http://mingyuliu.net/">Ming-Yu Liu</a><br>
                                <i>International Conference on Computer Vision</i> (ICCV), 2021 <br>
                                <a target="_blank" href="https://arxiv.org/abs/2104.07659">[arxiv preprint]</a>
                                <a target="_blank" href="https://nvlabs.github.io/GANcraft/">[project webpage and
                                    code]</a>
                            </p>
                        </td>
                    </tr>

                </table>
                <table id="workworkwork" width="100%" align="center" cellpadding="20"
                    style="background-color:#76E4E84D;">
                    <!-- <tr>
                        <td colspan="2" style="padding-bottom:0;">
                            <font size="3"><b>Interesting properties of Neural Networks, Efficient and Multi-Task
                                    Networks</b></font>
                            <hr>
                        </td>
                    </tr> -->

                    <tr id="gradinversion">
                        <td width="25%" valign="top">
                            <img loading="lazy" id="teaser" src="teasers/gradinversion.jpg">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>See through Gradients: Image Batch Recovery via GradInversion</b><br>
                                Hongxu Yin,
                                <strong>Arun Mallya</strong>,
                                <a target="_blank" href="http://latentspace.cc/arash_vahdat/">Arash Vahdat</a>,
                                Jose Alvarez,
                                <a target="_blank" href="https://research.nvidia.com/person/pavlo-molchanov">Pavlo
                                    Molchanov</a>,
                                <a target="_blank" href="http://jankautz.com/">Jan Kautz</a><br>
                                <i>Computer Vision and Pattern Recognition</i> (CVPR), 2021 <br>
                                <a target="_blank"
                                    href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.pdf">[paper]</a>
                            </p>
                        </td>
                    </tr>

                    <tr id="dream">
                        <td width="25%" valign="top">
                            <img loading="lazy" id="teaser" src="teasers/dream.jpg">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion (<span
                                        style="color:red">oral</span>)</b><br>
                                Hongxu Yin,
                                <a target="_blank" href="https://research.nvidia.com/person/pavlo-molchanov">Pavlo
                                    Molchanov</a>,
                                Zhizhong Li,
                                Jose Alvarez,
                                <strong>Arun Mallya</strong>,
                                Derek Hoiem,
                                Niraj Jha,
                                <a target="_blank" href="http://jankautz.com/">Jan Kautz</a><br>
                                <i>Computer Vision and Pattern Recognition</i> (CVPR), 2020 <br>
                                <a target="_blank" href="https://arxiv.org/abs/1912.08795">[arxiv preprint]</a>
                                <a target="_blank" href="https://github.com/NVlabs/DeepInversion">[code]</a>
                            </p>
                        </td>
                    </tr>

                    <tr id="piggyback">
                        <td width="25%" valign="top">
                            <img loading="lazy" id="teaser" src="teasers/piggyback.png">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>Piggyback: Adding Multiple Tasks to a Single, Fixed Network by Learning to
                                    Mask</b><br>
                                <strong>Arun Mallya</strong>, Dillon Davis, <a target="_blank"
                                    href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
                                <i>European Conference on Computer Vision</i> (ECCV), 2018 <br>
                                <a target="_blank" href="https://arxiv.org/abs/1801.06519">[arxiv preprint]</a>
                                <a target="_blank" href="https://github.com/arunmallya/piggyback18">[code]</a>
                            </p>
                        </td>
                    </tr>

                    <tr id="packnet">
                        <td width="25%" valign="top">
                            <img loading="lazy" id="teaser" src="teasers/packnet.png">
                        </td>
                        <td width="75%" valign="center">
                            <p>
                                <b>PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</b><br>
                                <strong>Arun Mallya</strong>, <a target="_blank"
                                    href="http://web.engr.illinois.edu/~slazebni/">Svetlana Lazebnik</a><br>
                                <i>Computer Vision and Pattern Recognition</i> (CVPR), 2018 <br>
                                <a target="_blank" href="https://arxiv.org/abs/1711.05769">[arxiv preprint]</a>
                                <a target="_blank" href="https://github.com/arunmallya/packnet">[code]</a>
                            </p>
                        </td>
                    </tr>

                </table>

                <hr>
                <table id="other_stuff" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <font size="5">Tutorials</font></br>
                        </td>
                    </tr>
                    <tr>
                        <td width="100%" valign="top">
                            <ol>
                                <li> <a target="_blank"
                                        href="https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/">Accelerating
                                        Computer Vision with Mixed Precision, ECCV 2020</a> </li>
                                <li> <a target="_blank"
                                        href="https://nvlabs.github.io/iccv2019-mixed-precision-tutorial/">Accelerating
                                        Computer Vision with Mixed Precision, ICCV 2019</a> </li>
                            </ol>
                        </td>
                    </tr>
                </table>

                <hr>
                <table id="other_stuff" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <font size="5">Writeups/Notes</font></br>
                            Hosted on <a target="_blank"
                                href="https://github.com/arunmallya/arunmallya.github.io/tree/master/writeups">github</a>.
                            Edit requests/additions/corrections are welcome.
                        </td>
                    </tr>
                    <tr>
                        <td width="100%" valign="top">
                            <ol>
                                <li> <a target="_blank" href="http://arunmallya.github.io/writeups/nn/backprop.html">A
                                        Backpropagation Refresher</a> </li>
                                <li> <a target="_blank"
                                        href="http://arunmallya.github.io/writeups/nn/lstm/index.html#/">An Illustrated
                                        Explanation of the LSTM Forward-Backward Pass</a> </li>
                                <li> <a target="_blank"
                                        href="http://slazebni.cs.illinois.edu/spring17/lec02_rnn.pdf">Introduction to
                                        RNNs</a> </li>
                                <li> <a target="_blank"
                                        href="http://slazebni.cs.illinois.edu/spring17/lec03_rnn.pdf">Introduction to
                                        RNNs - II</a> </li>
                                <li> <a target="_blank"
                                        href="https://gist.github.com/arunmallya/0e340cbc79c4f9545f97bf10d040cb65">Jupyter
                                        notebook to find Receptive Field Size and Effective Stride (supports dilated
                                        convs)</a> </li>
                                <li> <a target="_blank" href="http://jsfiddle.net/yces4vn9/43/">Visualization of neuron
                                        connections and receptive field of a CNN (including dilation)!</a> </li>
                            </ol>
                        </td>
                    </tr>
                </table>

                <table id="thanks" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <br>
                            <p align="right">
                                <font size="2">
                                    <a href="http://www.cs.berkeley.edu/~barron/">(imitation is the sincerest form of
                                        flattery)</a>
                                </font>
                            </p>
                        </td>
                    </tr>
                </table>

            </td>
        </tr>
    </table>
</body>

</html>
